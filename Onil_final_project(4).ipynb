{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hOGV43wAnyM"
      },
      "source": [
        "The motivation for this project comes from a keen interest in understanding how geography influences the performance of NBA players. By looking at career statistics like points per game, assists per game and rebounds per game, I aim to identify potential patterns and correlations between a player's state of origin and their performance on the court.\n",
        "\n",
        "The dataset for this analysis combines detailed career statistics of NBA players with demographic data from various states. This offers a comprehensive view of how regional factors might contribute to athletic success. My interest in this topic stems from a passion for basketball and a curiosity about the socio-economic and cultural factors that shape athletes.\n",
        "\n",
        "This project aims to provide insights valuable to talent scouts, coaches and sports analysts. It highlights the diversity of player performance across different states and adds to the broader conversation about developing sports talent in various regions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFw3E8TdHy4I"
      },
      "outputs": [],
      "source": [
        "# import calls\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LogNorm\n",
        "import sklearn.metrics as metrics\n",
        "import seaborn as sns;\n",
        "import cv2\n",
        "sns.axes_style(\"whitegrid\")\n",
        "sns.set_context(\"paper\")\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import add_dummy_feature\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "hGnXcOg2IPsE",
        "outputId": "3818edbd-b0a5-4a87-96ea-a0fcebacbb06"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7b84a0bc-f437-48af-8c34-057916780a7c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7b84a0bc-f437-48af-8c34-057916780a7c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wda0XJWaH4mt"
      },
      "outputs": [],
      "source": [
        "nba_df = pd.read_excel('NBA Players by State.xlsx')\n",
        "nba_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c6wqvoSh-Yr"
      },
      "outputs": [],
      "source": [
        "pop = pd.read_csv('uscities.csv')\n",
        "pop.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIUVui77JYSQ"
      },
      "outputs": [],
      "source": [
        "nba_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH2_iIk_IEai"
      },
      "outputs": [],
      "source": [
        "nba_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1wuHttroJNPR"
      },
      "outputs": [],
      "source": [
        "nba_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCor8NlONoIN"
      },
      "outputs": [],
      "source": [
        "nba_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V6VLdyJJfmm"
      },
      "outputs": [],
      "source": [
        "nba_df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvbqFoG-NlBg"
      },
      "outputs": [],
      "source": [
        "nba_df.rename(columns={'MP.1': 'MPPG', 'PTS.1': 'PTSPG', 'TRB.1': 'TRBPG', 'AST.1': 'ASTPG'}, inplace=True)\n",
        "nba_df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s43GVUk169cn"
      },
      "source": [
        "#Which states have produced the most NBA players?\n",
        "\n",
        "To answer this question, we extracted the State column from the NBA dataset and counted the frequency of each State which indicates the number of players from each state. Lastly, we sorted the frequencies in descending order to find out the state that produced the most NBA Players.\n",
        "\n",
        "From our analysis, we can see that California produced the most players."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HUBOa2Z9JtwG"
      },
      "outputs": [],
      "source": [
        "# extracting the states column from\n",
        "states = nba_df['State'].value_counts().sort_values(ascending=False)\n",
        "states.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkUgfduOAIri"
      },
      "source": [
        "#Is there a correlation between a player's birthplace (state) and the length of their NBA career (number of years played)?\n",
        "\n",
        "\n",
        "We follow the following algorithmic approach to check whether there is any correlation between a player's birthplace and the length of their NBA career.\n",
        "\n",
        "*   Create e dataframe, nba_df2, which only consists of the columns Players, Yrs and State from the nba_df dataset.\n",
        "\n",
        "*   Identify indices where numbers of years played is not numerical and store them in drop_indices\n",
        "\n",
        "*   Drop the rows with indices present in drop_indices\n",
        "\n",
        "*   Create a boolean mask to filter states with more than 100 players so that the average years played by each state is not skewed.\n",
        "\n",
        "\n",
        "*   Use the boolean mask, mask, to filter nba_df2 and create a new DataFrame, filtered_df, that only includes data from states with more than 100 players.\n",
        "\n",
        "*   Group filtered_df by State and calculate the mean of Yrs (average years played) for each state.\n",
        "\n",
        "\n",
        "*   Sort the results in descending order to find which states have the highest average years played.\n",
        "\n",
        "*   Use a bar plot to visualize the average years played by state, with states sorted by the average years played.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nOk4D2BLHeJ"
      },
      "outputs": [],
      "source": [
        "# creating nba_df2 that contains the columns\n",
        "# Player, Yrs and State\n",
        "nba_df2 = nba_df[['Player', 'Yrs', 'State']]\n",
        "\n",
        "# chekcing if there is any non-numerical data\n",
        "nba_df2['Yrs'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMgfYZArJ0Mz"
      },
      "outputs": [],
      "source": [
        "# identifying unwanted rows and dropping them by their indices\n",
        "drop_indices = nba_df2[nba_df2['Yrs'] == 'Yrs'].index\n",
        "nba_df2.drop(drop_indices, axis=0, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFA5335blGa_"
      },
      "outputs": [],
      "source": [
        "# creating a boolean mask\n",
        "mask = nba_df2[['State', 'Yrs']].groupby('State')[ 'Yrs'].count() > 100\n",
        "filtered_df = nba_df2[nba_df2['State'].isin(mask[mask].index)] # using the mask to output states that have a count of\n",
        "                                                              # more than 100\n",
        "# grouping the DataFrame\n",
        "filtered_df.groupby('State')['Yrs'].mean().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhfVRKC8P1C5"
      },
      "outputs": [],
      "source": [
        "# plotting the states vs average years played\n",
        "sns.barplot(filtered_df, x='State', y='Yrs', color='lightsteelblue', errorbar=None)\n",
        "\n",
        "# setting the labels\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('States')\n",
        "plt.ylabel('Average years played')\n",
        "plt.title('Average years played by state')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HZCeW1da7ew"
      },
      "source": [
        "According to the above analysis, Louisiana stands out with an average number of years played in NBA of almost 6.40 years. However, the other states are not much different from Louisiana. Other states include North Carolina with 5.99 years, Ohio with 5.73 years and California with 5.60 years. Thus, we have no significant evidence of the correlation between a playerâ€™s birthplace and career span in NBA as the averages across states are fairly similar."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r92iH190ATWM"
      },
      "source": [
        "#How do the career statistics (e.g., points per game, assists per game, rebounds per game) of NBA players vary by their state of origin?\n",
        "\n",
        "\n",
        "\n",
        "*   Create a DataFrame, nba_df3, having only the columns Player, State, PTSPG, ASTPG and TRBPG.\n",
        "\n",
        "*   Identify the rows that have unwanted values and store them in drop_indices. For instance, rows with value PTS in the PTSPG column.\n",
        "\n",
        "*   Drop the rows with indices present in drop_indices.\n",
        "\n",
        "*   Group the data by State and calculate the mean of PTSPG, ASTPG and TRBPG for each state.\n",
        "\n",
        "\n",
        "*   Create separate visualizations for each of these statistics:\n",
        "\n",
        "    *   Plot the average points per game by state.\n",
        "    *   Plot the average assists per game by state.\n",
        "    *   Plot the average rebounds per game by state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZPDRzsQDQi5i"
      },
      "outputs": [],
      "source": [
        "nba_df3 = nba_df[['Player', 'State', 'PTSPG', 'ASTPG', 'TRBPG']]\n",
        "nba_df3['PTSPG'].unique() # ensuring if there are any non-numeric values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqrasXmUC8Ug"
      },
      "outputs": [],
      "source": [
        "# setting out the only non-numeric value\n",
        "nba_df3[nba_df3['PTSPG'] == 'PTS']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IkFFplNdBCuq"
      },
      "outputs": [],
      "source": [
        "drop_indices = nba_df3[nba_df3['PTSPG'] == 'PTS'].index # indices to be dropped\n",
        "nba_df3.drop(drop_indices, axis=0, inplace=True)  # dropping the unwanted rows by indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y99eGSZCDOoo"
      },
      "outputs": [],
      "source": [
        "nba_df3.groupby('State')[['PTSPG', 'ASTPG', 'TRBPG']].mean().head() # mean of career statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq5yU4EvbvL6"
      },
      "outputs": [],
      "source": [
        "# plotting states vs average points per game\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(nba_df3, x='State', y='PTSPG', errorbar=None, color='coral')\n",
        "\n",
        "# setting up labels\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('States')\n",
        "plt.ylabel('Average points per game')\n",
        "plt.title('Average points per game by state')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u4sWzvWeP8t"
      },
      "source": [
        "The bar chart highlights the average points per game for NBA players by their state of origin. There's a noticeable difference across states. Hawaii shows the highest average points per game, while states like Alaska and Wyoming have lower averages. This suggests that player scoring performance varies widely depending on where they come from"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNgJiztQeVAi"
      },
      "outputs": [],
      "source": [
        "# plotting states vs average assists per game\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(nba_df3, x='State', y='ASTPG', errorbar=None, color='orange')\n",
        "\n",
        "# setting up labels\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('States')\n",
        "plt.ylabel('Average assists per game')\n",
        "plt.title('Average assists per game by state')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1mWjY-sfPXw"
      },
      "source": [
        "This bar chart displays the average assists per game by state of origin for NBA players. Here, Alaska stands out with the highest average assists per game. In contrast, states like Arizona and South Carolina have lower averages. This indicates that the ability to assist varies significantly among players from different states."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dBvQL0gxeVTC"
      },
      "outputs": [],
      "source": [
        "# plotting states vs average rebounds per game\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.barplot(nba_df3, x='State', y='TRBPG', errorbar=None, color='deeppink')\n",
        "\n",
        "# setting up labels\n",
        "plt.xticks(rotation=90)\n",
        "plt.xlabel('States')\n",
        "plt.ylabel('Average rebounds per game')\n",
        "plt.title('Average rebounds per game by state')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix3IV5nofWHf"
      },
      "source": [
        "The third bar chart illustrates the average rebounds per game by state of origin for NBA players. Hawaii again stands out, this time with the highest average rebounds per game. On the other hand, states like Alaska and Nevada have lower averages. This shows that players' rebounding performance varies considerably based on their state of origin.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXB2sZyqFwCI"
      },
      "source": [
        "# Predictive Modelling\n",
        "\n",
        "Below is the algorithmic approach for predictive modeling of city sizes based on PTS, AST, and TRB.\n",
        "\n",
        "*   Calculate the first quartile (q1) and third quartile (q3) of the city population densities.\n",
        "*   Implement the assign_city_size function:\n",
        "\n",
        "    *   Input: DataFrame containing city population densities.\n",
        "\n",
        "    *   Output: DataFrame with an additional column categorizing each city as 'small', 'medium', or 'big' based on density.\n",
        "\n",
        "\n",
        "*   Check for and handle NaN values in key features 'PTS', 'AST', and 'TRB'.\n",
        "\n",
        "\n",
        "*   Convert non-numeric types to floats.\n",
        "\n",
        "*   Extract the features 'PTS', 'AST', and 'TRB' from the merged DataFrame.\n",
        "*   Extract the target variable 'city_size' from the merged DataFrame.\n",
        "\n",
        "\n",
        "*   Use train_test_split to split the features and target into training and testing sets.\n",
        "\n",
        "\n",
        "*   Convert y_train and y_test to DataFrames to ensure they are in the correct format.\n",
        "*   Initialize the Decision Tree classifier:\n",
        "\n",
        "\n",
        "*   List itemSet the maximum depth to 15.\n",
        "\n",
        "*   Train the Decision Tree classifier on the training data and perform predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ub-ypNTzEGKl"
      },
      "outputs": [],
      "source": [
        "pop_df = pop[['city','state_name', 'population', 'density']]\n",
        "pop_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jJFM_-aHMPb"
      },
      "outputs": [],
      "source": [
        "nba_df = nba_df[['Player', 'PTS', 'AST', 'TRB', 'State', 'City']]\n",
        "nba_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f541RD9VHLoP"
      },
      "outputs": [],
      "source": [
        "# merging nba_df and pop_df on city and then state\n",
        "merged_df = pd.merge(nba_df, pop_df, left_on = ['City', 'State'], right_on=['city', 'state_name'], how='inner')\n",
        "\n",
        "# calculating upper and lower quartiles\n",
        "q1 = merged_df['density'].describe()[4]\n",
        "q3 = merged_df['density'].describe()[6]\n",
        "\n",
        "# defining function to categorize city_size based on pop. density\n",
        "def assign_city_size(density):\n",
        "  if density < q1:\n",
        "    return 1  # indicates small city\n",
        "  elif density > q3:\n",
        "    return 2  # indicates medium city\n",
        "  else:\n",
        "    return 3  # indicates big city\n",
        "\n",
        "# applying the function to the 'density' column\n",
        "merged_df['city_size'] = merged_df['density'].apply(assign_city_size)\n",
        "merged_df.drop(columns=['city', 'state_name'], axis=1, inplace=True)  # dropping the duplicate columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gqk1Xdi7IQzA"
      },
      "outputs": [],
      "source": [
        "# plotting pairplot\n",
        "mdf = merged_df[['PTS', 'AST', 'TRB', 'city_size']]\n",
        "plt.close('all')\n",
        "sns.pairplot(mdf, hue='city_size')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gc3apaLWSX29"
      },
      "outputs": [],
      "source": [
        "# making all the features numerical\n",
        "merged_df['PTS'] = merged_df['PTS'].astype(float)\n",
        "merged_df['AST'] = merged_df['AST'].astype(float)\n",
        "merged_df['TRB'] = merged_df['TRB'].astype(float)\n",
        "\n",
        "# setting NaN values to zero\n",
        "merged_df[['PTS', 'AST', 'TRB', 'city_size']] = merged_df[['PTS', 'AST', 'TRB', 'city_size']].fillna(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YvX3uHrcYRp"
      },
      "outputs": [],
      "source": [
        "# Define features and target\n",
        "feat = merged_df[['PTS', 'AST', 'TRB']].values\n",
        "target = merged_df['city_size'].values\n",
        "\n",
        "# Split the data\n",
        "x_train, x_test, y_train, y_test = train_test_split(feat, target, test_size=0.2, random_state=42)\n",
        "\n",
        "# Ensure y_train and y_test are 1D arrays\n",
        "y_train_df = pd.DataFrame(y_train)\n",
        "y_test_df = pd.DataFrame(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K33g9_aVRbMi"
      },
      "outputs": [],
      "source": [
        "# creating Decision Tree Classifier\n",
        "log_reg = DecisionTreeClassifier(max_depth=15)\n",
        "\n",
        "# fitting the model with the training data\n",
        "log_reg.fit(x_train, y_train_df)\n",
        "\n",
        "# outputing the scores of training and testing data\n",
        "print(\"Score on training data: \", log_reg.score(x_train, y_train_df))\n",
        "print(\"Score on testing data: \", log_reg.score(x_test, y_test_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKpdjDEQf90g"
      },
      "outputs": [],
      "source": [
        "# making predictions using training and testing data\n",
        "y_pred = log_reg.predict(x_train)\n",
        "y_predt = log_reg.predict(x_test)\n",
        "\n",
        "# printing classifier report of training data\n",
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQUGKpdaH6tl"
      },
      "outputs": [],
      "source": [
        "# printing classifier report of testing data\n",
        "print(classification_report(y_test, y_predt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZSJ0VoNL39i"
      },
      "source": [
        "The model does a decent job on the training data, showing an accuracy of 71%. But, there's a noticeable difference in precision and recall across different classes. For instance, class 3 has a high recall of 0.91. However, for classes 1 and 2, both precision and recall are just moderate.\n",
        "\n",
        "When we look at the testing data, the story changes. The accuracy drops to 40%, which means the model isn't doing well with new, unseen data. Specifically, for classes 1 and 2, both precision and recall are pretty low, indicating the model finds it hard to classify these classes correctly in the test set. Class 3 does a bit better with a precision of 0.51, recall of 0.63, and an F1-score of 0.56, but these numbers aren't particularly impressive either.\n",
        "\n",
        "Overall, it seems like the model is overfitting. It performs significantly better on the training data than on the testing data, which is a clear sign of this issue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOsViCDzf-Fu"
      },
      "outputs": [],
      "source": [
        "# confusion matrix of training data\n",
        "ConfusionMatrixDisplay.from_predictions(y_train, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AvOXuPWze0ay"
      },
      "outputs": [],
      "source": [
        "# confusion matrix of testing data\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_predt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SUifVQOO9se"
      },
      "source": [
        "The confusion matrix for the training data reveals that class 3 has the highest true positive rate with 1126 instances. This matches the high recall (0.91) observed earlier. For classes 1 and 2, there are more false positives and false negatives, which aligns with their moderate precision and recall scores.\n",
        "\n",
        "In the testing data, the confusion matrix shows a clear drop in true positives across all classes, especially for classes 1 and 2. This corresponds to the lower precision and recall scores for these classes. Class 3 maintains the highest number of true positives (196), but it also has a significant number of misclassifications. This indicates it performs better than classes 1 and 2, but still not well enough.\n",
        "\n",
        "These confusion matrices confirm the earlier observation that the model is overfitting. The model performs much better on the training data compared to the testing data. There are significant drops in true positive rates and increases in misclassifications in the test set, especially for classes 1 and 2. The model struggles to maintain its precision and recall when faced with new, unseen data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}